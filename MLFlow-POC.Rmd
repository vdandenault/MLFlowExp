---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.6.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

## MLFlow POC
Ref: 
-https://medium.com/towards-artificial-intelligence/how-i-started-tracking-my-ml-experiments-like-a-pro-dba184beb34
-https://github.com/terryz1/Iris_Classification/blob/master/iris_classification.ipynb

```{python}
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

from pandas.plotting import parallel_coordinates
import pandas as pd

import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import mlflow
import mlflow.sklearn
```

## Load Data

```{python}
def load_iris_data():
    url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
    attributes = ["sepal_length", "sepal_width", "petal_length", "petal_width", "class"]
    dataset = pd.read_csv(url, names = attributes)
    dataset.columns = attributes
    train, test = train_test_split(dataset, test_size = 0.2, stratify = dataset['class'], random_state = 42)
    X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]
    Y_train = train["class"]
    X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]
    Y_test = test["class"]
    input_data = (train, test, X_train, X_test, y_train, y_test)
    return input_data

data = load_iris_data()
train, test, X_train, X_test, y_train, y_test = data
print(train.head(10))
```

```{python}
# histograms
n_bins = 10
fig, axs = plt.subplots(2, 2)
axs[0,0].hist(train['sepal_length'], bins = n_bins);
axs[0,0].set_title('Sepal Length');
axs[0,1].hist(train['sepal_width'], bins = n_bins);
axs[0,1].set_title('Sepal Width');
axs[1,0].hist(train['petal_length'], bins = n_bins);
axs[1,0].set_title('Petal Length');
axs[1,1].hist(train['petal_width'], bins = n_bins);
axs[1,1].set_title('Petal Width');

# add some spacing between subplots
fig.tight_layout(pad=1.0);
```

```{python}
# boxplots using seaborn
fig, axs = plt.subplots(2, 2)
fn = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
cn = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']
sns.boxplot(x = 'class', y = 'sepal_length', data = train, order = cn, ax = axs[0,0]);
sns.boxplot(x = 'class', y = 'sepal_width', data = train, order = cn, ax = axs[0,1]);
sns.boxplot(x = 'class', y = 'petal_length', data = train, order = cn, ax = axs[1,0]);
sns.boxplot(x = 'class', y = 'petal_width', data = train,  order = cn, ax = axs[1,1]);
# add some spacing between subplots
fig.tight_layout(pad=1.0);
```

```{python}
sns.pairplot(train, hue="class", height = 2, palette = 'colorblind');
```

```{python}
corMatrix = train.corr()
sns.heatmap(corMatrix, annot = True, square = True);
```

```{python}
print(X_train.shape)
print(X_train)
```

```{python}
print(y_train.shape)
print(y_train)
```

```{python}
print(X_test.shape)
print(X_test)
```

```{python}
print(y_test.shape)
print(y_test)
```

## Decision Tree Model

```{python}
def train_predict_evaluate_dtree(params):
    with mlflow.start_run(run_name = "Decision Tree Classifier Experiments"):
        dtModel = DecisionTreeClassifier(random_state=42, max_leaf_nodes=params['leaf_nodes'], max_depth=params['max_depth'])
        dtModel.fit(X_train, y_train)
        y_pred = dtModel.predict(X_test)
        test_accuracy = metrics.accuracy_score(y_test, y_pred)
        test_f1_score = metrics.f1_score(y_test, y_pred, average='weighted')
        test_metrics = (test_accuracy, test_f1_score)
        print('The accuracy of the Decision Tree is',"{:.3f}".format(metrics.accuracy_score(y_pred,y_test)))
        
        mlflow.log_metric('test_accuracy' , test_accuracy)
        mlflow.log_metric('test_f1_score', test_f1_score)
        mlflow.log_param('leaf_nodes' , params.get('leaf_nodes'))
        mlflow.log_param('max_depth', params.get('max_depth'))
        
    return dtModel, test_metrics

params = {'leaf_nodes': 5, 'max_depth' :3}
dtModel, test_metrics = train_predict_evaluate_dtree(params)
```

```{python}
plt.figure(figsize = (10,8))
plot_tree(dtModel, feature_names = fn, class_names = cn, filled = True);
```
